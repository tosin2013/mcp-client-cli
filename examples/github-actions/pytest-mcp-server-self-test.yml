# GitHub Action for pytest-mcp-server Self-Testing
# Add this file to .github/workflows/ in the pytest-mcp-server repository

name: MCP Server Self-Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_types:
        description: 'Test types to run (comma-separated)'
        required: false
        default: 'functional,security,performance,issue-detection'
      confidence_threshold:
        description: 'Confidence threshold (0.0-1.0)'
        required: false
        default: '0.8'

jobs:
  self-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11, 3.12]
    
    steps:
    - name: Checkout pytest-mcp-server
      uses: actions/checkout@v4
      with:
        path: pytest-mcp-server
    
    - name: Checkout MCP Testing Framework
      uses: actions/checkout@v4
      with:
        repository: 'your-org/mcp-client-cli'  # Update with actual repo
        path: mcp-testing-framework
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install pytest-mcp-server dependencies
      run: |
        cd pytest-mcp-server
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f pyproject.toml ]; then pip install -e .; fi
    
    - name: Install MCP Testing Framework
      run: |
        cd mcp-testing-framework
        python -m pip install --upgrade pip
        pip install -e .
        pip install dagger-io pytest pytest-asyncio pytest-html
    
    - name: Run Self-Testing Workflow
      run: |
        cd mcp-testing-framework
        python scripts/pytest-mcp-server-workflow.py \
          --path ../pytest-mcp-server \
          --test-types ${{ github.event.inputs.test_types || 'functional,security,performance,issue-detection' }} \
          --confidence-threshold ${{ github.event.inputs.confidence_threshold || '0.8' }} \
          --output-dir test-results-${{ matrix.python-version }}
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-python-${{ matrix.python-version }}
        path: mcp-testing-framework/test-results-${{ matrix.python-version }}/
        retention-days: 30
    
    - name: Upload Integration Report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-report-python-${{ matrix.python-version }}
        path: mcp-testing-framework/test-results-${{ matrix.python-version }}/*.md
        retention-days: 30
    
    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read workflow results
          const resultsDir = 'mcp-testing-framework/test-results-${{ matrix.python-version }}';
          const resultsFiles = fs.readdirSync(resultsDir).filter(f => f.startsWith('workflow_results_'));
          
          if (resultsFiles.length > 0) {
            const resultsFile = path.join(resultsDir, resultsFiles[0]);
            const results = JSON.parse(fs.readFileSync(resultsFile, 'utf8'));
            
            const comment = `## 🧪 MCP Self-Testing Results (Python ${{ matrix.python-version }})
            
            **Overall Status**: ${results.overall_status}
            **Success Rate**: ${(results.summary?.success_rate * 100 || 0).toFixed(1)}%
            **Confidence**: ${(results.summary?.confidence || 0).toFixed(2)}
            
            ### Steps Executed:
            ${Object.entries(results.steps).map(([step, result]) => 
              `- ${result.status === 'SUCCESS' ? '✅' : '❌'} **${step}**: ${result.message}`
            ).join('\n')}
            
            ${results.summary?.recommendations ? `
            ### 💡 Recommendations:
            ${results.summary.recommendations.map(rec => `- ${rec}`).join('\n')}
            ` : ''}
            
            ---
            *Generated by pytest-mcp-server self-testing workflow*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  security-scan:
    runs-on: ubuntu-latest
    needs: self-test
    
    steps:
    - name: Checkout pytest-mcp-server
      uses: actions/checkout@v4
      with:
        path: pytest-mcp-server
    
    - name: Checkout MCP Testing Framework
      uses: actions/checkout@v4
      with:
        repository: 'your-org/mcp-client-cli'  # Update with actual repo
        path: mcp-testing-framework
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        cd mcp-testing-framework
        python -m pip install --upgrade pip
        pip install -e .
        pip install bandit safety
    
    - name: Run Security-Focused Testing
      run: |
        cd mcp-testing-framework
        python scripts/pytest-mcp-server-workflow.py \
          --path ../pytest-mcp-server \
          --test-types security \
          --confidence-threshold 0.9 \
          --output-dir security-results
    
    - name: Run Bandit Security Scan
      run: |
        cd pytest-mcp-server
        bandit -r . -f json -o ../mcp-testing-framework/security-results/bandit-report.json || true
    
    - name: Run Safety Check
      run: |
        cd pytest-mcp-server
        safety check --json --output ../mcp-testing-framework/security-results/safety-report.json || true
    
    - name: Upload Security Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-scan-results
        path: mcp-testing-framework/security-results/
        retention-days: 90

  performance-benchmark:
    runs-on: ubuntu-latest
    needs: self-test
    
    steps:
    - name: Checkout pytest-mcp-server
      uses: actions/checkout@v4
      with:
        path: pytest-mcp-server
    
    - name: Checkout MCP Testing Framework
      uses: actions/checkout@v4
      with:
        repository: 'your-org/mcp-client-cli'  # Update with actual repo
        path: mcp-testing-framework
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        cd mcp-testing-framework
        python -m pip install --upgrade pip
        pip install -e .
        pip install psutil memory-profiler
    
    - name: Run Performance Testing
      run: |
        cd mcp-testing-framework
        python scripts/pytest-mcp-server-workflow.py \
          --path ../pytest-mcp-server \
          --test-types performance \
          --confidence-threshold 0.8 \
          --output-dir performance-results
    
    - name: Upload Performance Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-benchmark-results
        path: mcp-testing-framework/performance-results/
        retention-days: 30

  generate-summary:
    runs-on: ubuntu-latest
    needs: [self-test, security-scan, performance-benchmark]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate Summary Report
      run: |
        echo "# 📊 pytest-mcp-server Testing Summary" > summary.md
        echo "" >> summary.md
        echo "**Date**: $(date -u)" >> summary.md
        echo "**Commit**: ${{ github.sha }}" >> summary.md
        echo "**Workflow**: ${{ github.workflow }}" >> summary.md
        echo "" >> summary.md
        
        echo "## 🧪 Test Results by Python Version" >> summary.md
        for dir in test-results-python-*; do
          if [ -d "$dir" ]; then
            version=$(echo $dir | sed 's/test-results-python-//')
            echo "### Python $version" >> summary.md
            if [ -f "$dir/workflow_results_*.json" ]; then
              # Extract key metrics from JSON (simplified)
              echo "- Status: Available in artifacts" >> summary.md
            else
              echo "- Status: No results found" >> summary.md
            fi
            echo "" >> summary.md
          fi
        done
        
        echo "## 🔒 Security Scan Results" >> summary.md
        if [ -d "security-scan-results" ]; then
          echo "- Security testing completed" >> summary.md
          echo "- Results available in artifacts" >> summary.md
        else
          echo "- Security scan not completed" >> summary.md
        fi
        echo "" >> summary.md
        
        echo "## ⚡ Performance Benchmark Results" >> summary.md
        if [ -d "performance-benchmark-results" ]; then
          echo "- Performance testing completed" >> summary.md
          echo "- Results available in artifacts" >> summary.md
        else
          echo "- Performance benchmark not completed" >> summary.md
        fi
        echo "" >> summary.md
        
        echo "## 📁 Available Artifacts" >> summary.md
        echo "- Test results for each Python version" >> summary.md
        echo "- Integration reports" >> summary.md
        echo "- Security scan results" >> summary.md
        echo "- Performance benchmark results" >> summary.md
        echo "" >> summary.md
        
        echo "---" >> summary.md
        echo "*Generated by pytest-mcp-server self-testing workflow*" >> summary.md
    
    - name: Upload Summary Report
      uses: actions/upload-artifact@v3
      with:
        name: testing-summary
        path: summary.md
        retention-days: 90
    
    - name: Create Issue on Failure
      if: failure() && github.event_name == 'schedule'
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: '🚨 Scheduled MCP Self-Testing Failed',
            body: `The scheduled MCP self-testing workflow failed.
            
            **Workflow Run**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            **Commit**: ${{ github.sha }}
            **Date**: ${new Date().toISOString()}
            
            Please review the workflow logs and test results to identify and resolve any issues.
            
            ---
            *This issue was automatically created by the self-testing workflow.*`,
            labels: ['bug', 'testing', 'automated']
          }); 